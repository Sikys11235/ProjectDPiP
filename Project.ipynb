{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ourri\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end date by mohl být dnešek\n",
    "start date fix\n",
    "fool-proof input \n",
    "###### \n",
    "Vyzkoušet si to na training data\n",
    "Vybrat si ML model\n",
    "Jak vizualizace?\n",
    "#########\n",
    "přidat config a dokumentaci\n",
    "další soubory\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple (AAPL): 7.28%\n",
    "Microsoft (MSFT): 6.60%\n",
    "Amazon (AMZN): 2.68%\n",
    "NVIDIA (NVDA): 2.02%\n",
    "Alphabet Class A (GOOGL): 1.82%\n",
    "Berkshire Hathaway (BRK.B): 1.70%\n",
    "Alphabet Class C (GOOG): 1.60%\n",
    "Meta (META), formerly Facebook, Class A: 1.55%\n",
    "UnitedHealth Group (UNH): 1.34%\n",
    "Exxon Mobil (XOM): 1.32%\n",
    "Johnson & Johnson (JNJ): 1.25%\n",
    "Tesla (TSLA): 1.25%\n",
    "JPMorgan Chase (JPM): 1.18%\n",
    "Procter & Gamble (PG): 1.07%\n",
    "Visa Class A (V): 1.07%\n",
    "Eli Lilly (LLY): 0.93%\n",
    "Mastercard Class A (MA): 0.92%\n",
    "Home Depot (HD): 0.87%\n",
    "Merck (MRK): 0.87%\n",
    "Chevron Corporation (CVX): 0.83%\n",
    "AbbVie (ABBV): 0.78%\n",
    "PepsiCo (PEP): 0.77%\n",
    "Broadcom (AVGO): 0.74%\n",
    "Coca-Cola Company (KO): 0.72%\n",
    "Costco (COST): 0.64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_stocks = {\n",
    "    'AAPL': 'Apple Inc.',\n",
    "    'MSFT': 'Microsoft Corporation',\n",
    "    'AMZN': 'Amazon.com, Inc.',\n",
    "    'GOOGL': 'Alphabet Inc.',\n",
    "    'FB': 'Facebook, Inc.',\n",
    "    'BRK-B': 'Berkshire Hathaway Inc.',\n",
    "    'V': 'Visa Inc.',\n",
    "    'TSLA': 'Tesla, Inc.',\n",
    "    'JPM': 'JPMorgan Chase & Co.',\n",
    "    'JNJ': 'Johnson & Johnson',\n",
    "    \"PG\" : \"Procter and Gamble\",\n",
    "    \"MA\" : \"Mastercard Class A\",\n",
    "    \"MRK\" : \"Merck\",\n",
    "    \"KO\" : \"Coca-Cola Company\",\n",
    "    \"NVDA\" :\"NVIDIA\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    base_url = \"https://query1.finance.yahoo.com/v7/finance/download/\"\n",
    "    start_date_timestamp = int(pd.Timestamp(start_date).timestamp())\n",
    "    end_date_timestamp = int(pd.Timestamp(end_date).timestamp())\n",
    "    params = {\n",
    "        'period1': start_date_timestamp,\n",
    "        'period2': end_date_timestamp,\n",
    "        'interval': '1d',\n",
    "        'events': 'history',\n",
    "        'includeAdjustedClose': 'true'\n",
    "    }\n",
    "    \n",
    "    url = f\"{base_url}{ticker}\"\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        stock_data = pd.read_csv(StringIO(response.text))\n",
    "        return stock_data\n",
    "    else:\n",
    "        print(\"Error fetching data:\", response.status_code)\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular stock tickers:\n",
      "AAPL: Apple Inc.\n",
      "MSFT: Microsoft Corporation\n",
      "AMZN: Amazon.com, Inc.\n",
      "GOOGL: Alphabet Inc.\n",
      "FB: Facebook, Inc.\n",
      "BRK-B: Berkshire Hathaway Inc.\n",
      "V: Visa Inc.\n",
      "TSLA: Tesla, Inc.\n",
      "JPM: JPMorgan Chase & Co.\n",
      "JNJ: Johnson & Johnson\n",
      "PG: Procter and Gamble\n",
      "MA: Mastercard Class A\n",
      "MRK: Merck\n",
      "KO: Coca-Cola Company\n",
      "NVDA: NVIDIA\n"
     ]
    }
   ],
   "source": [
    "print(\"Popular stock tickers:\")\n",
    "for ticker, company in popular_stocks.items():\n",
    "    print(f\"{ticker}: {company}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data: 403\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ticker = input(\"Enter the stock ticker from the list above: \")\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Validate the ticker input\n",
    "if ticker not in popular_stocks:\n",
    "    print(\"Error: Invalid ticker. Please choose a ticker from the list of popular stocks.\")\n",
    "else:\n",
    "    # Set the start date to January 1, 1995\n",
    "    start_date = \"1995-01-01\"\n",
    "\n",
    "    stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "    print(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################\n",
    "Yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\ourri\\anaconda3\\lib\\site-packages (0.2.18)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (2.28.1)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (4.9.1)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (2023.3)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (37.0.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (4.11.1)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2022.9.14)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    stock_data = stock.history(start=start_date, end=end_date)\n",
    "    return stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular stock tickers:\n",
      "AAPL: Apple Inc.\n",
      "MSFT: Microsoft Corporation\n",
      "AMZN: Amazon.com, Inc.\n",
      "GOOGL: Alphabet Inc.\n",
      "FB: Facebook, Inc.\n",
      "BRK-B: Berkshire Hathaway Inc.\n",
      "V: Visa Inc.\n",
      "TSLA: Tesla, Inc.\n",
      "JPM: JPMorgan Chase & Co.\n",
      "JNJ: Johnson & Johnson\n"
     ]
    }
   ],
   "source": [
    "popular_stocks = {\n",
    "    'AAPL': 'Apple Inc.',\n",
    "    'MSFT': 'Microsoft Corporation',\n",
    "    'AMZN': 'Amazon.com, Inc.',\n",
    "    'GOOGL': 'Alphabet Inc.',\n",
    "    'FB': 'Facebook, Inc.',\n",
    "    'BRK-B': 'Berkshire Hathaway Inc.',\n",
    "    'V': 'Visa Inc.',\n",
    "    'TSLA': 'Tesla, Inc.',\n",
    "    'JPM': 'JPMorgan Chase & Co.',\n",
    "    'JNJ': 'Johnson & Johnson',\n",
    "    # Add more stocks as needed\n",
    "}\n",
    "\n",
    "print(\"Popular stock tickers:\")\n",
    "for ticker, company in popular_stocks.items():\n",
    "    print(f\"{ticker}: {company}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2020-01-02 00:00:00-05:00   28.299999   28.713333   28.114000   28.684000   \n",
      "2020-01-03 00:00:00-05:00   29.366667   30.266666   29.128000   29.534000   \n",
      "2020-01-06 00:00:00-05:00   29.364668   30.104000   29.333332   30.102667   \n",
      "2020-01-07 00:00:00-05:00   30.760000   31.441999   30.224001   31.270666   \n",
      "2020-01-08 00:00:00-05:00   31.580000   33.232666   31.215334   32.809334   \n",
      "...                               ...         ...         ...         ...   \n",
      "2023-04-28 00:00:00-04:00  160.899994  165.000000  157.320007  164.309998   \n",
      "2023-05-01 00:00:00-04:00  163.169998  163.279999  158.830002  161.830002   \n",
      "2023-05-02 00:00:00-04:00  161.880005  165.490005  158.929993  160.309998   \n",
      "2023-05-03 00:00:00-04:00  160.009995  165.000000  159.910004  160.610001   \n",
      "2023-05-04 00:00:00-04:00  162.710007  162.949997  159.649994  161.199997   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2020-01-02 00:00:00-05:00  142981500        0.0           0.0  \n",
      "2020-01-03 00:00:00-05:00  266677500        0.0           0.0  \n",
      "2020-01-06 00:00:00-05:00  151995000        0.0           0.0  \n",
      "2020-01-07 00:00:00-05:00  268231500        0.0           0.0  \n",
      "2020-01-08 00:00:00-05:00  467164500        0.0           0.0  \n",
      "...                              ...        ...           ...  \n",
      "2023-04-28 00:00:00-04:00  122515800        0.0           0.0  \n",
      "2023-05-01 00:00:00-04:00  109015000        0.0           0.0  \n",
      "2023-05-02 00:00:00-04:00  128259700        0.0           0.0  \n",
      "2023-05-03 00:00:00-04:00  119728000        0.0           0.0  \n",
      "2023-05-04 00:00:00-04:00   95108500        0.0           0.0  \n",
      "\n",
      "[841 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "ticker = input(\"Enter the stock ticker from the list above: \")\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Validate the ticker input\n",
    "if ticker not in popular_stocks:\n",
    "    print(\"Error: Invalid ticker. Please choose a ticker from the list of popular stocks.\")\n",
    "else:\n",
    "    # Set the start date to January 1, 1995\n",
    "    start_date = \"2020-01-01\"\n",
    "\n",
    "    stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "    print(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ourri\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Here, we have preprocessed the data and prepared it for the implementation of ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the stock data:\n",
      "Open            0\n",
      "High            0\n",
      "Low             0\n",
      "Close           0\n",
      "Volume          0\n",
      "Dividends       0\n",
      "Stock Splits    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in the stock data:\")\n",
    "print(stock_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.interpolate(method='linear', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_close_prices = stock_data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_adj_close_prices = scaler.fit_transform(adj_close_prices)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\ourri\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ourri\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: numpy, keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.3\n",
      "    Uninstalling numpy-1.19.3:\n",
      "      Successfully uninstalled numpy-1.19.3\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "Successfully installed keras-2.12.0 numpy-1.23.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, look_back=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - 1):\n",
    "        X.append(data[i:(i + look_back), 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "X, y = create_dataset(scaled_adj_close_prices, look_back)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_train_pred = lr_model.predict(X_train)\n",
    "lr_test_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_train_data = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "arima_test_data = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "arima_model = ARIMA(arima_train_data, order=(5, 1, 0))\n",
    "arima_model_fit = arima_model.fit()\n",
    "arima_test_pred = arima_model_fit.forecast(steps=len(y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tohle trvá tak 8 minut hehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "671/671 - 2s - loss: 0.0441 - 2s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "671/671 - 1s - loss: 0.0011 - 762ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "671/671 - 1s - loss: 7.7790e-04 - 765ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "671/671 - 1s - loss: 7.4573e-04 - 710ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "671/671 - 1s - loss: 7.1322e-04 - 695ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "671/671 - 1s - loss: 7.3909e-04 - 696ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "671/671 - 1s - loss: 7.1386e-04 - 665ms/epoch - 991us/step\n",
      "Epoch 8/50\n",
      "671/671 - 1s - loss: 7.0823e-04 - 681ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "671/671 - 1s - loss: 6.9185e-04 - 672ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "671/671 - 1s - loss: 6.8352e-04 - 685ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "671/671 - 1s - loss: 6.5426e-04 - 669ms/epoch - 997us/step\n",
      "Epoch 12/50\n",
      "671/671 - 1s - loss: 6.6217e-04 - 672ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "671/671 - 1s - loss: 6.7399e-04 - 678ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "671/671 - 1s - loss: 6.4784e-04 - 721ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "671/671 - 1s - loss: 6.4607e-04 - 653ms/epoch - 973us/step\n",
      "Epoch 16/50\n",
      "671/671 - 1s - loss: 6.2349e-04 - 664ms/epoch - 990us/step\n",
      "Epoch 17/50\n",
      "671/671 - 1s - loss: 6.5717e-04 - 689ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "671/671 - 1s - loss: 6.4900e-04 - 654ms/epoch - 974us/step\n",
      "Epoch 19/50\n",
      "671/671 - 1s - loss: 6.6249e-04 - 711ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "671/671 - 1s - loss: 6.5622e-04 - 712ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "671/671 - 1s - loss: 6.4962e-04 - 662ms/epoch - 987us/step\n",
      "Epoch 22/50\n",
      "671/671 - 1s - loss: 6.2944e-04 - 647ms/epoch - 965us/step\n",
      "Epoch 23/50\n",
      "671/671 - 1s - loss: 6.1604e-04 - 659ms/epoch - 982us/step\n",
      "Epoch 24/50\n",
      "671/671 - 1s - loss: 6.4956e-04 - 666ms/epoch - 992us/step\n",
      "Epoch 25/50\n",
      "671/671 - 1s - loss: 6.4174e-04 - 658ms/epoch - 981us/step\n",
      "Epoch 26/50\n",
      "671/671 - 1s - loss: 6.2448e-04 - 659ms/epoch - 983us/step\n",
      "Epoch 27/50\n",
      "671/671 - 1s - loss: 6.2134e-04 - 671ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "671/671 - 1s - loss: 6.3874e-04 - 661ms/epoch - 985us/step\n",
      "Epoch 29/50\n",
      "671/671 - 1s - loss: 6.3705e-04 - 651ms/epoch - 971us/step\n",
      "Epoch 30/50\n",
      "671/671 - 1s - loss: 6.6986e-04 - 655ms/epoch - 976us/step\n",
      "Epoch 31/50\n",
      "671/671 - 1s - loss: 6.9094e-04 - 658ms/epoch - 981us/step\n",
      "Epoch 32/50\n",
      "671/671 - 1s - loss: 6.1804e-04 - 662ms/epoch - 986us/step\n",
      "Epoch 33/50\n",
      "671/671 - 1s - loss: 6.5213e-04 - 714ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "671/671 - 1s - loss: 6.4969e-04 - 840ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "671/671 - 1s - loss: 6.4521e-04 - 715ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "671/671 - 1s - loss: 6.4626e-04 - 809ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "671/671 - 1s - loss: 6.1944e-04 - 696ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "671/671 - 1s - loss: 6.6021e-04 - 664ms/epoch - 989us/step\n",
      "Epoch 39/50\n",
      "671/671 - 1s - loss: 6.6159e-04 - 663ms/epoch - 988us/step\n",
      "Epoch 40/50\n",
      "671/671 - 1s - loss: 6.3791e-04 - 660ms/epoch - 984us/step\n",
      "Epoch 41/50\n",
      "671/671 - 1s - loss: 6.1906e-04 - 668ms/epoch - 996us/step\n",
      "Epoch 42/50\n",
      "671/671 - 1s - loss: 6.4288e-04 - 658ms/epoch - 980us/step\n",
      "Epoch 43/50\n",
      "671/671 - 1s - loss: 6.4136e-04 - 662ms/epoch - 987us/step\n",
      "Epoch 44/50\n",
      "671/671 - 1s - loss: 6.5323e-04 - 654ms/epoch - 975us/step\n",
      "Epoch 45/50\n",
      "671/671 - 1s - loss: 6.4755e-04 - 659ms/epoch - 982us/step\n",
      "Epoch 46/50\n",
      "671/671 - 1s - loss: 6.1548e-04 - 658ms/epoch - 981us/step\n",
      "Epoch 47/50\n",
      "671/671 - 1s - loss: 6.4797e-04 - 658ms/epoch - 981us/step\n",
      "Epoch 48/50\n",
      "671/671 - 1s - loss: 6.5530e-04 - 663ms/epoch - 988us/step\n",
      "Epoch 49/50\n",
      "671/671 - 1s - loss: 6.2833e-04 - 671ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "671/671 - 1s - loss: 6.3876e-04 - 651ms/epoch - 970us/step\n",
      "21/21 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, input_shape=(1, look_back)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=1, verbose=2)\n",
    "\n",
    "lstm_train_pred = lstm_model.predict(X_train_lstm)\n",
    "lstm_test_pred = lstm_model.predict(X_test_lstm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of performance of the models using MSE criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Train MSE: 0.0005472281013616903\n",
      "Linear Regression Test MSE: 0.0003937881433643679\n",
      "ARIMA Test MSE: 8753.234356366584\n",
      "LSTM Train MSE: 0.0006319465512655069\n",
      "LSTM Test MSE: 0.00039587975716020007\n"
     ]
    }
   ],
   "source": [
    "lr_train_mse = mean_squared_error(y_train, lr_train_pred)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_test_pred)\n",
    "arima_test_mse = mean_squared_error(arima_test_data, arima_test_pred)\n",
    "lstm_train_mse = mean_squared_error(y_train, lstm_train_pred)\n",
    "lstm_test_mse = mean_squared_error(y_test, lstm_test_pred)\n",
    "\n",
    "print(\"Linear Regression Train MSE:\", lr_train_mse)\n",
    "print(\"Linear Regression Test MSE:\", lr_test_mse)\n",
    "print(\"ARIMA Test MSE:\", arima_test_mse)\n",
    "print(\"LSTM Train MSE:\", lstm_train_mse)\n",
    "print(\"LSTM Test MSE:\", lstm_test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ještě zkusíme GARCH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arch\n",
      "  Downloading arch-5.5.0-cp39-cp39-win_amd64.whl (856 kB)\n",
      "     -------------------------------------- 856.6/856.6 kB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from arch) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from arch) (1.9.1)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from arch) (1.4.4)\n",
      "Requirement already satisfied: statsmodels>=0.11 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from arch) (0.13.2)\n",
      "Collecting property-cached>=1.6.4 (from arch)\n",
      "  Downloading property_cached-1.6.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from pandas>=1.0->arch) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from pandas>=1.0->arch) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from statsmodels>=0.11->arch) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from statsmodels>=0.11->arch) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.11->arch) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\ourri\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.11->arch) (1.16.0)\n",
      "Installing collected packages: property-cached, arch\n",
      "Successfully installed arch-5.5.0 property-cached-1.6.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      6,   Neg. LLF: 7467115509.657264\n",
      "Iteration:      2,   Func. Count:     17,   Neg. LLF: 1273984.6483499703\n",
      "Iteration:      3,   Func. Count:     28,   Neg. LLF: 1329.5601865413073\n",
      "Iteration:      4,   Func. Count:     37,   Neg. LLF: 38867.891386069285\n",
      "Iteration:      5,   Func. Count:     47,   Neg. LLF: 139292.05673360682\n",
      "Iteration:      6,   Func. Count:     53,   Neg. LLF: 385350885.700281\n",
      "Iteration:      7,   Func. Count:     60,   Neg. LLF: -1162.9796682371482\n",
      "Iteration:      8,   Func. Count:     66,   Neg. LLF: -511.29385212521606\n",
      "Iteration:      9,   Func. Count:     73,   Neg. LLF: -1167.911602601789\n",
      "Iteration:     10,   Func. Count:     78,   Neg. LLF: -1167.9140761208698\n",
      "Iteration:     11,   Func. Count:     83,   Neg. LLF: -1167.9140743297842\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -1167.9140770407435\n",
      "            Iterations: 11\n",
      "            Function evaluations: 84\n",
      "            Gradient evaluations: 11\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already downloaded the stock data using the download_stock_data function\n",
    "stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "\n",
    "# Create a 'returns' column\n",
    "stock_data['returns'] = stock_data['Close'].pct_change().dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(stock_data['returns'].dropna(), test_size=0.2, shuffle=False)\n",
    "\n",
    "# Fit the GARCH model\n",
    "model_garch = arch_model(train_data, vol='Garch', p=1, q=1, rescale= False)\n",
    "results_garch = model_garch.fit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GARCH konvergoval, ale nevím co to znamená lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ourri\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\ourri\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\ourri\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\ourri\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "841    0.005159\n",
       "842    0.001862\n",
       "843   -0.000833\n",
       "844    0.000950\n",
       "845    0.002014\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_arima_model = ARIMA(stock_data['returns'], order=(5, 1, 0)).fit()\n",
    "future_forecast = best_arima_model.forecast(steps=5)\n",
    "future_forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
